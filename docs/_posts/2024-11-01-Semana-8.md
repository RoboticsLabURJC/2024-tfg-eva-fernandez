---
title: "Semana 8. Montado una aplicación para elegir movimientos"
categories:
  - Weblog
tags:
  - Gazebo Harmonic
  - ROS2 Humble Hawksbill
  - Python
  - JSON
---

La tarea principal de esta semana era montar una aplicación en python capaz de hacer elegir al usuario el moviento de la articulación en el tiempo deseado para que el NAO lo replicara. Por ejemplo: "Segundo 10, hombro izquierdo a 0.5".

Para ello, eran necesarias 2 "sub-aplicaciones":
1. Aplicación para elegir el movimiento y el tiempo con GUI
2. Programa que lee esa información y se la manda a NAO

Para la primera, había que construir una interfaz de usuario cómoda y fácil para elegir este movimiento y el tiempo, y, después, que esta información se volcase en unfichero JSON, que después sería leído por la segunda aplicación, encargada de hacer que el NAO replique la secuencia de movimientos elegida.

Pero, antes de ponerme con esta tarea principal, hice que el mundo de NAO tuviese una métrica, ccosa que nos ayudaría más adelante a la hora de hacer que NAO caminase.

Esta tarea fue bastante sencilla, pero algo larga, porque para hacerlo había que editar el sdf del mundo y añadir los siguientes elementos:
1. Una línea recta con marcas visuales que indiquen la distancia
2. Una línea lateral con marcas visuales que indiquen la distancia
3. Un círculo para controlar curvas

El procedimeinto fue bastante sencillo, comenzando primero por la línea recta.
Para hacerla, primero quité el grid del suelo para que se viera mejor, después, pensé que sería una buena idea hacer la línea negra de 20 metros de largo, con su centro en el origen  (dónde está NAO) y, depués, para las marcas visuales, unas pequeñas líneas amarillas cada 5 metros:

![linea recta](/2024-tfg-eva-fernandez/images/semana-8/nao_suelo.png)

Una vez hecha, decidí volver a poner el grid para asegurarme de que no se salía de los límites del suelo:

![linea con grid](/2024-tfg-eva-fernandez/images/semana-8/nao_grid.png)

Lo que me sirvió para darme cuenta que el grid también es una gran ayuda para las marcas visuales, debido a que, si contamos los cuadrados hasta la primera marca, hay exactamente 5 cuadrados, lo que nos indica que cada cuadrado tiene un metro de lado. Así que decidí dejar este grid.

Después, hice el círculo, de 0.5 metros de radio:

![circulo](/2024-tfg-eva-fernandez/images/semana-8/nao_circulo.png)

Y, por último, para la segunda línea, simplemente giré la primera:

![linea lateral](/2024-tfg-eva-fernandez/images/semana-8/nao_lateral.png)

Una vez modificado el mapa, podía empezar con la tarea principal de la semana.

Para esta tarea, recordé que en el tercer año de la carrera, en la asignatura "Modelado y simulación de robots" utilizábamos pybullet para simular robots y sus movimmientos, así que me pareció buena idea utilizarlo para poder ver las posiciones del NAO en tiempo real a la hora de elegirlas.

Sin embargo, había un problema: Pybullet no me leía el modelo SDF del NAO, ya que trabaja con modelos URDF.

Así que, buscando por internet, encontré el mismo modelo de NAO, pero en urdf.

Después de un buen rato modificando a mano este modelo para que funcionase, obtuve el siguiente resultado en pybullet:

![nao](/2024-tfg-eva-fernandez/images/semana-8/nao_pybullet.png)

Que, aunque no tuviese color, tenía las articulaciones que necesitaba, muestro a continuación todos los joints de este modelo, los cuales se necesita el índice para controlarlos con los sliders(explicado más adelante):

![joints 1](/2024-tfg-eva-fernandez/images/semana-8/joints_1.png)
![joints 2](/2024-tfg-eva-fernandez/images/semana-8/joints_2.png)

Después de cargar el modelo, cree un total de 26 sliders: 24 para cada articulación necesaria (las mostradas la semana anterior, para esto necesitaba los índices de los joints), otro para seleccionar el segundo exacto donde quieres esas posiciones y, el último, para confirmar la selección y salir del programa, no sin antes escribir los datos de cada una de las 24 articulaciones en el fichero movement_pattern.json, el cual guarda:
1. Nombre de la articulación
2. Posición de la articulación
3. TIempo en el que quieres llegar a la posicion

Una vez implementado todo esto, obtuve el siguiente resultado:

<video width="800" controls>
  <source src="/2024-tfg-eva-fernandez/images/semana-8/nao_json.webm" type="video/webm">
  Your browser does not support the video tag.
</video>

Ya sólo faltaba hacer que ROS leyese este fichero json e hiciera que NAO replicase los movimientos necesarios en cada instante de tiempo.

Para ello, lo que hice fue crear un nuevo fichero python en el mismo workspace de siempre, llamado moving_in_pattern.py, que, lo que hace es, a la hora de crear el nodo, leer el fichero JSON y para cada una de las articulaciones se guarda el nombre para crear el publicador y la posición para crear el mensaje, después, en el main, anntes de publicar, se lee de nuevo el fichero para coger el tiempo, dormir ese número de segundos y por último publicar todos los mensajes.

El resultado fue el siguiente (cabe destacar que el json usado aquí es distinto al generado en el video anterior, el cual debe mover al NAO al cabo de 3 segundos)

<video width="800" controls>
  <source src="/2024-tfg-eva-fernandez/images/semana-8/nao_moviendose_ros.webm" type="video/webm">
  Your browser does not support the video tag.
</video>

Un problema que tienen estos programas es que sólo se puede guardar UNA posición de las articulaciones para el fichero JSON, cosa que debo arreglar para que en el mismo fichero se puedan tener varias posiciones. Pero esta tarea, por tiempo, prefiero dejarla para la siguiente semana del desarrollo del tfg.

También me terminé de leer [este tfg](https://gsyc.urjc.es/jmplaza/students/pfc-caminata_nao-2010.pdf). Y comencé [este otro](https://gsyc.urjc.es/jmplaza/students/pfc-nao_gazebo-fperez-2015.pdf)


